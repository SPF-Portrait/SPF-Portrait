<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning. ">
  <meta name="keywords" content="customize characters wearing any combination of garments!">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/dressing.svg ">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-1 publication-title"><span style="
              font-weight: bold;
              background: linear-gradient(107.54deg, #0078d4 .39%, #8661c5 51.23%, #ff9349 100%);
              -webkit-background-clip: text;
              color: transparent;
            ">
      SPF-Portrait
    </span>: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning </h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=XpaHZywAAAAJ&hl=zh-CN">Xiaole Xian</a><sup>★ ♱ ♡</sup>,</span>
              <span class="author-block">
                <a href="https://lzc-sg.github.io/">Zhichao Liao</a><sup>★ ♱ ♤</sup>,</span>
              <span class="author-block">
                <a>Qingyu Li</a><sup>♢</sup>,
              </span>
              <span class="author-block">
                <a>Wenyu Qin</a><sup>♢</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=P6MraaYAAAAJ&view_op=list_works&sortby=pubdate">Pengfei Wan</a><sup>♢</sup>,
              </span>
              <span class="author-block">
                <a href="https://csse.szu.edu.cn/pages/user/index?id=659">Weicheng Xie</a><sup>✉ ♡</sup>,</span>
              </span>
              <br>
              <span class="author-block">
                <a href="https://www.sigs.tsinghua.edu.cn/cl/main.htm">Long Zeng</a><sup>✉ ♤</sup>,
              </span>
              <span class="author-block">
                <a href="https://csse.szu.edu.cn/pages/user/index?id=594">Linlin Shen</a><sup>♡</sup>,
              </span>
              <span class="author-block">
                <a href="https://me.tsinghua.edu.cn/info/1097/1576.htm">Pingfa Fengn</a><sup>♤</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>★</sup>Co-first authors (equal contribution)</span>&nbsp;
              <span class="author-block"><sup>✉</sup>Corresponding author</span>&nbsp
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>♱</sup>Work done during internship at KwaiVGI, Kuaishou Technology</span>&nbsp
            </div>
    
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>♡</sup>Shenzhen University,</span>&nbsp;
              <span class="author-block"><sup>♤</sup>Tsinghua University,</span>&nbsp;
              <span class="author-block"><sup>♢</sup>Kuaishou Technology</span>&nbsp
            </div>


            <!-- <div class="is-size-5 publication-authors">
              <p style="color: green;">We'd like to thank Yongsheng Dong and Guoliang Xu, for the valuable help on data processing.</p>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2504.00396"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"> 
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/KwaiVGI/SPF-Portrait" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming soon)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/github_image/teaser.jpg" alt="" class="wide-image"/>

        <h2 class="content has-text-justified">
          <p>
            <b><i>SPF-Portrait: </i></b> We introduce a training pipeline eliminates the pollution during human attributes of fine-tuning.
          </p>
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->



  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-2" style="font-family: Comic Sans MS"><div class="x-gradient-font">Abstract</div></h2>
          <div class="content has-text-justified">
            <p>
              Fine-tuning a pre-trained Text-to-Image (T2I) model on a tailored portrait dataset is the mainstream method for text-driven customization of portrait attributes.
              Due to <b><i>Semantic Pollution</i></b> during fine-tuning, existing methods struggle to maintain the original model's behavior and achieve incremental learning while customizing target attributes.
              To address this issue, we propose  <b><i>SPF-Portrait</i></b>, a pioneering work to purely understand customized semantics while eliminating semantic pollution in text-driven portrait customization. 
              In our SPF-Portrait, we propose a dual-path pipeline that introduces the original model as a reference for the conventional fine-tuning path.
              Through contrastive learning, we ensure adaptation to target attributes and purposefully align other unrelated attributes with the original portrait.
              We introduce a novel Semantic-Aware Fine Control Map, which represents the precise response regions of the target semantics, to spatially guide the alignment process between the contrastive paths.
              This alignment process not only effectively preserves the performance of the original model but also avoids over-alignment.
              Furthermore, we propose a novel response enhancement mechanism to reinforce the performance of target attributes, while mitigating representation discrepancy inherent in direct cross-modal supervision.
              Extensive experiments demonstrate that SPF-Portrait achieves state-of-the-art performance.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Paper poster -->
  <section class="section hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <h2 class="title is-2" style="font-family: Comic Sans MS"><div class="x-gradient-font">SPF-Portrait Overview</div></h2>
            <div class="content has-text-justified">
              Given a batch data of image-text pairs, SPF-Portrait can adapt the T2I model to the new concepts without semantic pollution. 
              The fine-tuned T2I model can achieve the target attributes while <b>inherits the original model's pretrained priors</b> including text understanding, layout details and so on.
            </div>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <img src="static/github_image/pipeline.png" alt="" width="1600" />
              </td>
            </div>
          </div>
  </section>
  <!--End paper poster -->

  <!-- Paper poster -->
  <section class="section hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <h2 class="title is-2" style="font-family: Comic Sans MS"><div class="x-gradient-font">More visualization Results</div></h2>
              <td colspan="3">
                <img src="static/github_image/sota.png" alt="" width="1600" />
              </td>
             <div class="content has-text-justified">
            <b>Qualitative Comparisons with SOTA methods</b>. We compare ours with naive fine-tuning, PEFT-based methods (LoRA, AdaLoRA) and the decoupled methods (Tokencompose, Magenet). Please zoom in for more details. 
               Our approach not only achieves the target semantics, but also better preserves the behavior of the original model. 
            </div>
            </div>
          </div>
  </section>
  <!--End paper poster -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <!-- <h2 class="title">BibTeX</h2> -->
      <h2 class="title is-2" style="font-family: Comic Sans MS"><div class="x-gradient-font">BibTeX</div></h2>
      <p>
        If you find this project useful in your research, please consider cite:
      </p>
      <pre><code>
      @article{xian2025spf,
        title={SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning},
        author={Xian, Xiaole and Liao, Zhichao and Li, Qingyu and Qin, Wenyu and Wan, Pengfei and Xie, Weicheng and Zeng, Long and Shen, Linlin and Feng, Pingfa},
        journal={arXiv preprint arXiv:2504.00396},
        year={2025}
        }
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <!-- <div class="content has-text-centered">
        <a class="icon-link"
           href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div> -->
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This project is intended solely for academic research and effect demonstration. No commercial benefits are derived from it. Most models used are from internet (Civiti, Huggingface), and
              all portraits are generated.
            </p>
            <!-- <p>
              This website is licensed under a <a rel="license"
                                                  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p> -->
            <p>
              Website source code based on the <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>
